{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find-mismatched-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## steps\n",
    "## 1. Split the first and second strings\n",
    "## 2. find the difference between the two strings after split\n",
    "## 3. return the mismatched_strin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mismatched_words(string1, string2):\n",
    "   words1=set(string1.lower().split())\n",
    "   words2=set(string2.lower().split())\n",
    "   difference=words1.symetric_difference(words2)\n",
    "   return difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_values(numbers):\n",
    "  for key,val in numbers.items():\n",
    "    return val[0],val[1]=val[1],val[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Is Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isMatch(s:str, p:str):\n",
    "    match = re.fullmatch(p, s)\n",
    "    return bool(match)\n",
    "\n",
    "isMatch(s,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def str_map(string1, string2):\n",
    "    return Counter(string1)==Counter(string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1 = 'qwe'\n",
    "string2 = 'asd'\n",
    "\n",
    "str_map(string1, string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_accumulator(s):\n",
    "    a=s.split('')\n",
    "    ele=int(a)\n",
    "    return ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty separator",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m123.0045\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdigit_accumulator\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m, in \u001b[0;36mdigit_accumulator\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdigit_accumulator\u001b[39m(s):\n\u001b[1;32m----> 2\u001b[0m     a\u001b[38;5;241m=\u001b[39m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     ele\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(a)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ele\n",
      "\u001b[1;31mValueError\u001b[0m: empty separator"
     ]
    }
   ],
   "source": [
    "s = \"123.0045\"\n",
    "digit_accumulator(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interview query Write a query to identify the names of users who placed less than 3 orders or ordered less than $500 worth of product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select name from products a join users b on a.user_id=b.id\n",
    "group by name \n",
    "having count(*)<3 or sum(a.order_total)<500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.merge(products,users,right_on=\"user_id\",left_on=\"user_id\",how=\"inner\")\n",
    "df.groupby(\"name\").agg(counts:{'count','user_id','sum':'order_total'}).reset_index()\n",
    "df[(df['count']<3)|(df['order_total']<500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=products.join(users,product.user_id==user.user_id,how=\"inner\")\n",
    "df_2=df.groupby(\"name\").agg((count(col(\"*\")).alias(\"total_count\"))|(sum(col(\"order_total\"))).alias(\"total_order\")).show()\n",
    "df_2.filter((col(\"total_count\")<3)|(col(\"order_total\")<500)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select AVG(b.downloads),b.download_data,a.\n",
    "from accounts a join downloads b on a.account_id=b.account_id\n",
    "group by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.merge(accouts,downloads,right_on=\"account_id\",left_on=\"account_id\",how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=accounts.join(downloads,accounts.account_id==downloads.account_id,how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer to Roman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "III\n",
      "LVIII\n",
      "MCMXCIV\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def int_to_roman(num):\n",
    "    if not 1 <= num <= 3999:\n",
    "        raise ValueError(\"Input must be between 1 and 3999\")\n",
    "    \n",
    "    values = [\n",
    "        (1000, 'M'), (900, 'CM'), (500, 'D'), (400, 'CD'),\n",
    "        (100, 'C'),  (90, 'XC'),  (50, 'L'),  (40, 'XL'),\n",
    "        (10, 'X'),   (9, 'IX'),   (5, 'V'),   (4, 'IV'),\n",
    "        (1, 'I')\n",
    "    ]\n",
    "    \n",
    "    roman_numeral = \"\"\n",
    "    for value, symbol in values:\n",
    "        while num >= value:\n",
    "            roman_numeral += symbol\n",
    "            num -= value\n",
    "    return roman_numeral\n",
    "print(int_to_roman(3))   # III\n",
    "print(int_to_roman(58))  # LVIII\n",
    "print(int_to_roman(1994))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversations Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do you think the distribution of the number of conversations created by each user per day looks like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select count(*),user1,user2,to_char(date,'day')\n",
    "from messages group by 2,3,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['day']=messages['day'].dt.day\n",
    "messages.groupby([\"user1\",\"user2\",\"day\"]).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.withColumn(\"day\",day('day'))\n",
    "messages.groupby(\"user1\",\"user2\",\"day\").agg(count(col(\"*\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a query to get the distribution of the number of conversations created by each user by day in the year 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select count(*),user1,user2,to_char(date,'day')\n",
    "from messages where extract(year from date)=2024 group by 2,3,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['day']=message['date'].dt.day\n",
    "\n",
    "message[message['date'].dt.year==2024].groupby(['user1','user2','day']).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.withColumn(\"day\",day(\"date\"))\n",
    "message.filter(year(col('date')==2024)).groupby(\"user1\",\"user2\",\"day\").agg(count(col(\"*\")).alias(\"total_counts\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.interviewquery.com/questions/sequentially-fill-in-integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH NumberCounts AS (\n",
    "  SELECT\n",
    "    int_numbers,\n",
    "    COUNT(*) AS count\n",
    "  FROM\n",
    "    tbl_numbers\n",
    "  GROUP BY\n",
    "    int_numbers\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  int_numbers * count AS repeated_number\n",
    "FROM\n",
    "  NumberCounts\n",
    "WHERE\n",
    "  int_numbers = count;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=tbl_numbers.copy()\n",
    "count=df.groupby(\"int_number\").size()\n",
    "df_1=df[df['int_numbers']==count]\n",
    "df_1['int_numbers']*count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_numbers.groupby(\"int_numbers\").agg(count(col(\"*\")).alias(\"count\")).select(\"count\").show()\n",
    "tbl_numbers.filter(col(\"int_numbers\")==count).filter((col(\"int_numbers\")*count).alias(\"total_count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select DATEDIFF(unit, start_dt, end_dt) AS duration from rides\n",
    "where DATEDIFF(hour, 'start_dt',end_dt)>2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=rides.copy()\n",
    "df['hour']=(df['start_dt'].dt.hour-df['end_dt'].dt.hour)\n",
    "df_1=df[df['hour']>2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides.withColumn(\"new\",col('start_dt')-col('end_dt'))\n",
    "rides.withColumn(\"hour\",hour(\"new\"))\n",
    "rides.filter(col(\"hour\")>2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Find the Index with Equal Left and Right Sum\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "def find_equal_sum_index(nums):\n",
    "    total_sum=sum(nums)\n",
    "    left_sum=0\n",
    "    for i,num in enumerate(nums):\n",
    "        if left_sum==(total_sum-left_sum-num):\n",
    "            return i\n",
    "        left_sum+=num\n",
    "    return -1\n",
    "nums = [8, 2, 3, 6, 5, 2, 5, 9, 1, 2]\n",
    "index = find_equal_sum_index(nums)\n",
    "print(index)\n",
    "\n",
    "# Time complexity is O(n), where 'n' is the length of the input list nums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longest Increasing Subsequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = [10, 9, 2, 5, 3, 3, 7, 101, 18]\n",
    "def longest_increasing_subsequence(nums):\n",
    "    if not nums:\n",
    "        return 0\n",
    "    dp=[1]*len(nums)\n",
    "    for i in range(len(nums)):\n",
    "        for j in range(i):\n",
    "            if nums[i]>nums[j]:\n",
    "                dp[i]=max(dp[i],dp[j]+1)\n",
    "    return max(dp)\n",
    "    \n",
    "longest_increasing_subsequence(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Weighted Average Campaigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT campaign_name,round(sum(num_clicks*num_users)/num_users,2) from email_campaigns_table\n",
    "group by 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=email_campaigns_table.copy()\n",
    "df['weighted']=df['num_clicks']*df['num_users']\n",
    "df.groupby('campaign_name')['weighted'].sum().round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"weighted_average\",col(\"num_clicks\")*col(\"num__users\"))\n",
    "df.groupby('campaign_name').agg(sum(col(\"weighted_average\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def can_shift(A, B):\n",
    "  if len(A) != len(B):\n",
    "    return False\n",
    "\n",
    "  # Check if B is a substring of A + A\n",
    "  return B in (A + A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Top N Frequent Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def n_frequent_words(posting,N):\n",
    "  words=Counter(posting.split()).most_common(n)\n",
    "  return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 5), ('sauna', 2), ('of', 2)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posting = \"\"\"\n",
    "Herbal sauna uses the healing properties of herbs in combination with distilled water.   \n",
    "The water evaporates and distributes the effect of the herbs throughout the room.   \n",
    "A visit to the herbal sauna can cause real miracles, especially for colds. \n",
    "\"\"\"  \n",
    "n = 3\n",
    "\n",
    "n_frequent_words(posting,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT count(case when event_name='post_submit' then 1 else 0)/count(*),extract(day from created_at)\n",
    "from events\n",
    "where created_at between '01-01-2020' and '01-31-2020'\n",
    "group by 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liker's Likers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT\n",
    "    COUNT(DISTINCT ll.liker_id) AS likers_of_likers_count\n",
    "FROM\n",
    "    Likes l\n",
    "JOIN\n",
    "    Likes ll ON l.liker_id = ll.likee_id\n",
    "WHERE\n",
    "    l.liker_id IN (SELECT liker_id FROM Likes GROUP BY liker_id HAVING COUNT(likee_id) = 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employee Project Budgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT p.id AS project_id, p.title, (p.budget / COUNT(DISTINCT ep.employee_id)) AS budget_per_employee \n",
    "FROM projects p\n",
    "INNER JOIN employees_projects ep ON p.id = ep.project_id\n",
    "GROUP BY p.id, p.title\n",
    "ORDER BY budget_per_employee DESC \n",
    "LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.merge(projects,employees_project,right_on=\"id\",left_on=[\"project_id\"],how=\"inner\")\n",
    "df.grpub(['id','title']).apply(lambda x:x['budge']/x['employee_id'].nunique()).sort_values(by=['budget_per_employee'],ascending=False).head(5).reset_index(name=\"budget_per_employee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=projects.join(employee,projects.id==employee.project_id,how=\"inner\")\n",
    "df.groupby(\"id\",\"title\").agg(col(\"budge\")/countDistinct(\"employee_id\").as(\"budget_per_employee\")).sort(desc(\"budget_per_employee\")).limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Month Over Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH MonthlyRevenue AS (\n",
    "    SELECT\n",
    "        STRFTIME('%Y-%m', transaction_date) AS month,\n",
    "        SUM(price) AS revenue\n",
    "    FROM\n",
    "        transactions t\n",
    "    JOIN\n",
    "        products p ON t.product_id = p.product_id\n",
    "    WHERE\n",
    "        STRFTIME('%Y', transaction_date) = '2019'\n",
    "    GROUP BY\n",
    "        month\n",
    "),\n",
    "MonthlyRevenueLagged AS (\n",
    "    SELECT\n",
    "        month,\n",
    "        revenue,\n",
    "        LAG(revenue, 1, 0) OVER (ORDER BY month) AS previous_month_revenue\n",
    "    FROM\n",
    "        MonthlyRevenue\n",
    ")\n",
    "SELECT\n",
    "    month,\n",
    "    ROUND((revenue - previous_month_revenue) * 100.0 / previous_month_revenue, 2) AS month_over_month_change\n",
    "FROM\n",
    "    MonthlyRevenueLagged\n",
    "WHERE previous_month_revenue > 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Impossibly Iterative Fibonacci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fib(n) -> int:\n",
    "    if n<=1:\n",
    "        return n\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biggest Tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_tips(user_ids, tips):\n",
    "    if not user_ids or not tips or len(user_ids) != len(tips):\n",
    "        return None\n",
    "\n",
    "    user_tip_totals = defaultdict(int)  # Initialize with default value 0\n",
    "\n",
    "    for user_id, tip in zip(user_ids, tips):\n",
    "        user_tip_totals[user_id] += tip\n",
    "\n",
    "    if not user_tip_totals: #handles the case where the lists are empty after the initial check.\n",
    "        return None\n",
    "\n",
    "    return max(user_tip_totals, key=user_tip_totals.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrambled Tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_trip(flights):\n",
    "    if not flights:\n",
    "        return []\n",
    "\n",
    "    flight_dict = dict(flights)  # Direct dictionary creation from list of pairs\n",
    "    departures = {f[0] for f in flights}\n",
    "    arrivals = {f[1] for f in flights}\n",
    "\n",
    "    start = (departures - arrivals).pop() if departures - arrivals else flights[0][0] if flights else None\n",
    "\n",
    "    if start is None:\n",
    "        return []\n",
    "\n",
    "    result = []\n",
    "    current = start\n",
    "\n",
    "    while current in flight_dict:\n",
    "        result.append([current, flight_dict[current]])\n",
    "        current = flight_dict[current]\n",
    "\n",
    "    return result if len(result) == len(flights) else flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Unique Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH UniqueCategoriesPerOrder AS (\n",
    "    SELECT\n",
    "        a.user_id,\n",
    "        a.order_id,\n",
    "        COUNT(DISTINCT b.item_category) AS unique_categories\n",
    "    FROM\n",
    "        user_orders a\n",
    "    JOIN\n",
    "        ordered_items b\n",
    "    ON\n",
    "        a.order_id = b.order_id\n",
    "    GROUP BY\n",
    "        a.user_id, a.order_id\n",
    "),\n",
    "AverageCategoriesPerUser AS (\n",
    "    SELECT\n",
    "        user_id,\n",
    "        AVG(unique_categories) AS avg_unique_categories\n",
    "    FROM\n",
    "        UniqueCategoriesPerOrder\n",
    "    GROUP BY\n",
    "        user_id\n",
    ")\n",
    "SELECT\n",
    "    user_id,\n",
    "    avg_unique_categories\n",
    "FROM\n",
    "    AverageCategoriesPerUser\n",
    "ORDER BY\n",
    "    avg_unique_categories DESC\n",
    "LIMIT 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Average Sales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH RankedSales AS (\n",
    "    SELECT\n",
    "        product_id,\n",
    "        sale_date,\n",
    "        sales,\n",
    "        ROW_NUMBER() OVER (PARTITION BY product_id ORDER BY sale_date) AS rn,\n",
    "        LAG(sales, 1, 0) OVER (PARTITION BY product_id ORDER BY sale_date) AS prev_sales,\n",
    "        LAG(sales, 2, 0) OVER (PARTITION BY product_id ORDER BY sale_date) AS prev_prev_sales\n",
    "    FROM\n",
    "        Sales\n",
    ")\n",
    "SELECT\n",
    "    product_id,\n",
    "    sale_date,\n",
    "    sales,\n",
    "    (sales * 0.5 + prev_sales * 0.3 + prev_prev_sales * 0.2) AS weighted_moving_average\n",
    "FROM\n",
    "    RankedSales\n",
    "WHERE\n",
    "    rn >= 3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolating Missing Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def interpolating_missing_temperatures(temperature_data: pd.DataFrame):\n",
    "    temperature_data=df_filled.copy()\n",
    "    df_filled = df.interpolate(method='linear')\n",
    "    return df_filled\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Logins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT USER_ID,COUNT(*)\n",
    "from user_logins\n",
    "where login_date=\"01-01-2022\"\n",
    "group by USER_ID\n",
    "having count(*)=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_logins=user_logins[user_logins['login_date']==\"01-01-2022\"]\n",
    "user_logins.groupby(\"user_id\").apply(lambda x:len(x)>1)\n",
    "## doubt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_logins.groupby(\"user_id\").agg(count(col(\"*\")).alias(\"counts\")).filter((col(\"counts\")==1)&(col(\"login_date\")==\"01-01-2022\")).select(col(\"user_ids\"),col(\"counts\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def inject_frequency(sentence, discard_list):\n",
    "    filtered_sentence=''.join(c for c in sentence if c not in discard_list)\n",
    "    char_counts=Counter(filtered_sentence)\n",
    "    output_sentence=''\n",
    "    for char,items in char_counts.items():\n",
    "        output_sentence+=f\"{char}{items}\"\n",
    "return output_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String Palindromes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer String Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_str_addition(int_str):\n",
    "    try:\n",
    "        numbers = [int(num) for num in input_str.split('+')]\n",
    "        return sum(numbers)\n",
    "    except ValueError:\n",
    "        return \"Invalid input: Please use integers separated by '+'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given two strings A and B, write a function can_shift to return whether or not A can be shifted some number of places to get B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def can_shift(A, B):\n",
    "  if len(A) != len(B):\n",
    "    return False\n",
    "\n",
    "  # Check if B is a substring of A + A\n",
    "  return B in (A + A)\n",
    "A = 'abcde'\n",
    "B = 'cdeab'\n",
    "can_shift(A, B) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Spent on Products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT b.iitem,sum(price) FROM users a right join purchases b on a.user_id=b.user_id\n",
    "where year(a.registration_date)==2022\n",
    "group by b.item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.merge(users,purchases,on=\"user_id\",how=\"right\")\n",
    "df['date']=pd.to_datetime(df['date'],errors=\"coerce\")\n",
    "df=df[df['date']dt.year=2022]\n",
    "df.groupby('item')['price'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=users.join(purchases,users.user_id==purchases.user_id,how=\"right\")\n",
    "df=df.filter(year('date')==2022)\n",
    "df.groupby('item').agg(sum(\"price\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Names Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def first_name_only(users_df):\n",
    "    return users_df['name'].str.split('',n=2,expand=True).get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Words with Stems\n",
    "roots = [\"cat\", \"bat\", \"rat\"]\n",
    "sentence = \"the cattle was rattled by the battery\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words(roots, sentence):\n",
    "  l1=[]\n",
    "  words=sentence.split()\n",
    "  for word in words:\n",
    "    for root in roots:\n",
    "      if root in word:\n",
    "        l1.append(root)\n",
    "        break\n",
    "      else:\n",
    "        l1.append(word)\n",
    "    return \" \".join(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String Subsequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def string_subsequence(string1,string2):\n",
    "    i,j=0,0\n",
    "    while i<len(string1) and j<len(string2):\n",
    "        if string1[i]==string2[j]:\n",
    "            i+=1\n",
    "        j+=1\n",
    "    return i==len(string1)\n",
    "string1 = \"abc\"\n",
    "string2 = \"aaaaf\"\n",
    "print(string_subsequence(string1, string2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "numlists = [ [1,2,3,4,5], [3,1,2,5,4], [1,2,3,4,5,6,7], \n",
    "[99, 320, 400, 100.25, 55.2, 0.1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_fifths(numlists):\n",
    "    for ele in numlists:\n",
    "        elemenets=ele[4]\n",
    "    return elemenets\n",
    "\n",
    "list_fifths(numlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_resumes(existing_ids, names, urls):\n",
    "    existing_ids = [15234, 20485, 34536, 95342, 94857]\n",
    "\n",
    "names = ['Calvin', 'Jason', 'Cindy', 'Kevin']\n",
    "urls = [\n",
    "    'domain.com/resume/15234', \n",
    "    'domain.com/resume/23645', \n",
    "    'domain.com/resume/64337', \n",
    "    'domain.com/resume/34536',\n",
    "]\n",
    "def new_resumes(existing_ids,names,urls):\n",
    "    urls=str(urls)\n",
    "    urls_numbers=[]\n",
    "    combining=[]\n",
    "    url_split=re.search(r'/(\\d+)$', url)\n",
    "    for ele in url_split:\n",
    "        ele=ele.group(1)\n",
    "        urls_numbers.append(ele)\n",
    "    for ele in existing_ids:\n",
    "        if ele in urls_numbers:\n",
    "            combining.append((existing_ids,names))\n",
    "    return combining\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targeted sum  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_sum_closest(nums, target):\n",
    "    if i == len(nums):\n",
    "        return 1 if sum == target else 0\n",
    "    return target_sum(nums, target, i + 1, sum + nums[i]) + target_sum(nums, target, i + 1, sum - nums[i])\n",
    "\n",
    "nums = [1, 1, 1, 1, 1]\n",
    "target = 3\n",
    "print(target_sum(nums, target))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Missing Element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_element_removed(full, missing):\n",
    "    return set(full)^set(missing)\n",
    "one_element_removed(full,missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HR Salary Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select job_title,sum(salary),sum(overtime_rate),sum(overtime_hours) from employees\n",
    "group by job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees.groupby(\"job_title\").agg({\"salary\":\"sum\",\"overtime_rate\":\"sum\",\"overtime_hours\":\"sum\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees.groupby(\"job_title\").agg(sum(\"salary\").alias(\"overtime_sum_salary\"),sum(\"overtime_rate\").alias(\"sum_overtime_rate\"),sum(\"sum_overtime_rate\").alias(\"overtime_hours\")).select(col(\"job_title\"),col(\"overtime_hours\"),col(\"sum_overtime_rate\"),col(\"overtime_sum_salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Orders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select * from transactions t\n",
    "join users u\n",
    "on t.id=u.id\n",
    "where to_chart(create_at,'year') in (2019,2020)\n",
    "group by id.\n",
    "having count(*)>3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user['year']=users['created_at'].dt.year\n",
    "user=user[user['year'].isin([2019,2020])]\n",
    "user.groupby(\"id\").apply(lambda x:len(x)>3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.withColumn(\"year\",Year(created_at))\n",
    "users.filter(col(\"year\").isin([2019,2020])).groupby(col(\"id\")).agg(count(col(\"*\")).alias(\"total_count\")).filter(col(\"total_count\")>3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique Work Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT employee_id, COUNT(DISTINCT work_date) AS days_worked\n",
    "FROM projects\n",
    "GROUP BY employee_id\n",
    "ORDER BY employee_id;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects=projects.groupby(\"employee_id\")[\"work_date\"].nunique().sort_values().reset_index()\n",
    "projects.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects.groupby(\"employee_id\").agg(countDistinct(col(\"work_date\")).alias(\"works_date\")).sort(asc(\"employee_id\")).select(distinct(\"work_date\"),col(\"employee_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prime to N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prime_numbers(N):\n",
    "    primes = []\n",
    "  for num in range(2, N+1):\n",
    "    is_prime = True\n",
    "    for i in range(2, int(num**0.5) + 1):\n",
    "      if num % i == 0:\n",
    "        is_prime = False\n",
    "        break\n",
    "    if is_prime:\n",
    "      primes.append(num)   \n",
    "      return primes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def bernoulli_sample(p):\n",
    "   if random.random() < p:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg Friend Requests By Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select avg(a.quantity),b.gender\n",
    "from transaction a join users b on a.id=b.id\n",
    "group by b.gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=transaction.join(user,on=\"id\",how=\"inner\")\n",
    "df.groupby(\"gender\")[\"quantity\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.join(user,on=\"id\",how=\"inner\").groupby(\"gender\").agg(avg(col(\"quantity\")).alias(\"quantitys\")).select(col(\"user_id\"),col(\"quantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'c': 2, 'o': 2, 'n': 2, 's': 2, 'u': 1, 'i': 1})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'concussion'\n",
    "Counter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m val\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m      6\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m val\n\u001b[1;32m----> 7\u001b[0m \u001b[43mfirst_uniq_char\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m, in \u001b[0;36mfirst_uniq_char\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m      3\u001b[0m ele\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(s))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key,val \u001b[38;5;129;01min\u001b[39;00m ele:\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mval\u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m:\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
      "\u001b[1;31mTypeError\u001b[0m: '<=' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def first_uniq_char(s):\n",
    "    ele=list(enumerate(s))\n",
    "    for key,val in ele:\n",
    "        if val<=1:\n",
    "            return val\n",
    "first_uniq_char(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def coin_toss(tosses, probability_of_heads):\n",
    "    results = []\n",
    "    for _ in range(num_tosses):\n",
    "        if random.random() < probability_heads:\n",
    "            results.append('H')\n",
    "        else:\n",
    "            results.append('T')\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECTive Wine Connoisseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT id\n",
    "from wines\n",
    "where ash<2.4 and color_intensity<3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines.filter(col(\"ash\")>2.4) & (col(\"color_intensity\")<3 &(col()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines[(wines[\"ash\"]>2.5)&(wines[\"color_intensity\"]<3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 3 Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select * from(select rank() over(partition by user_id order by downloads)r from download_facts)\n",
    "where r=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_facts.groupby('user_id')['downloads'].rank(method='min', ascending=False)\n",
    "result_df = download_facts[download_facts['rank'] == 3]\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_facts.withColumn(\"rank\",over(Window.partitionBy(\"user_id\").over(orderBy downloads)))\n",
    "download_facts.filter(col(\"rank\")==3).select(col(\"*\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.interviewquery.com/questions/friendship-timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling Bank Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT\n",
    "    to_char(deposit_date,'%Y-%M-%D') as date\n",
    "    AVG(deposit_amount) OVER (ORDER BY deposit_date ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) AS three_day_avg\n",
    "FROM\n",
    "    deposits;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=depsoits.copy()\n",
    "df['three_day_avg']=df['deposit_amount'].rolling(window=3).mean()\n",
    "df['date']=pd.to_datetime(df['date'],format=\"%Y-%M-%D\",errors=\"coerce\")\n",
    "df[['date','three_day_avg']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deposits.withColumn(\"three_day_avg\",avg(deposit_amount).over(order by deposit_date rows between 2 preceding and current now))\n",
    "deposit.withColum(\"deposit_date\",date_format(\"deposit_date\",\"%Y-%M-%D\"))\n",
    "deposit.select('deposit_date','three_day_avg').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max(nums):\n",
    "    return max(nums)\n",
    "find_max(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Transactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT sum(price) as total_cost,u.name,u.user_id\n",
    "FROM transactions table t\n",
    "join products table p on t.id=p.id\n",
    "join users u on u.id=p.id\n",
    "group by u.uname,u.user_id\n",
    "order by sum(price) desc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.merge(products,users,right_on=[\"id\"],left_on=[\"id\"],how=\"inner\")\n",
    "df.groupb(['user_name','user_id'])[\"price\"].sum().reset_index()\n",
    "df.sort_values(by=['price'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=products.join(users,product.id==users.id,how=\"inner\")\n",
    "df.groupby('user_name','user_id').agg(sum(col(\"price\")).alias(\"total_price\")).show()\n",
    "df.sort(desc(\"price\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Payments Received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT COUNT(DISTINCT c.customer_id)\n",
    "FROM customers c\n",
    "JOIN transactions t ON c.customer_id = t.customer_id\n",
    "WHERE c.signup_date >= '2020-01-01' AND c.signup_date < '2020-02-01'  -- Signed up in January 2020\n",
    "  AND t.transaction_date >= c.signup_date AND t.transaction_date < DATE_ADD(c.signup_date, INTERVAL 30 DAY) -- Within 30 days of signup\n",
    "  AND t.status = 'Successful' -- Only successful transactions\n",
    "GROUP BY c.customer_id\n",
    "HAVING SUM(t.amount) > 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.merge(customers,transactions,right_on=[\"customer_id\"],left_on=[\"customer_id\"],how=\"inner\")\n",
    "df=df[df['signup_date']>='2020-01-01')&(df['signup_date']<='2020-02-01')&(df['transaction_date']>='signup_date')&(df['transaction_date']<pd.timedelta(days=30)+df['signup_date']&(df['status']=='Successful'))]\n",
    "df.groupby('customer_id')['customer_id'].nunique().filter(lambda x:x['amount'].sum(()>100)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = transactions.withColumn(\"transaction_date\", col(\"transaction_date\").cast(\"date\"))\n",
    "\n",
    "result = (customers.join(transactions, \"customer_id\")\n",
    "          .filter((col(\"signup_date\") >= lit(\"2020-01-01\")) & (col(\"signup_date\") < lit(\"2020-02-01\")) &  # Signup in Jan 2020\n",
    "                  (col(\"transaction_date\") >= col(\"signup_date\")) & (col(\"transaction_date\") < date_add(col(\"signup_date\"), lit(30))) & # Within 30 days\n",
    "                  (col(\"status\") == lit(\"Successful\")))  # Successful transactions only\n",
    "          .groupBy(\"customer_id\")\n",
    "          .agg(sum(\"amount\").alias(\"total_amount\"))\n",
    "          .filter(col(\"total_amount\") > 100)\n",
    "          .agg(countDistinct(\"customer_id\").alias(\"customer_count\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select * from \n",
    "(select rank() over(partition by user_id order by product_id) as r\n",
    "from transactions) where r=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows=Windows.partitionBy(\"user_id\").orderBy(\"product_id\")\n",
    "df.withColumn(\"r\",rank().over(windows))\n",
    "df.filter(col(\"r\")==3).select(col(\"*\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rank'] = df.groupby('user_id')['product_id'].rank(method='dense', ascending=False)\n",
    "# Filter for rows with rank 3\n",
    "df_filtered = df[df['rank'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select * from users\n",
    "group by id\n",
    "having count(*)>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.groupby(\"id\").agg(count(col(\"*\")).alias(\"total_count\")).filter(col(\"total_count\")>1).select(col(\"*\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.groupby(\"id\").apply(lambda x:len(x)>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Active Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select count(id),platform\n",
    "from events\n",
    "where to_char('created_at','year')=2020\n",
    "group by platform;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events['year']=events['created_at'].dt.year\n",
    "events[events[events['year']==2020]\n",
    "events.groupby('platform')['id'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.withColumns(\"Year\",year(created_at))\n",
    "events.groupby('platform').agg(count(col(\"*\")).alias(\"conts_platform\")).filter(col(\"year\")==2020).select(col(\"platform\"),col(\"conts_platform\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum to Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_sum(numbers):\n",
    "    pairs = []\n",
    "  seen = set()  # Keep track of numbers we've seen\n",
    "\n",
    "  for num in numbers:\n",
    "    complement = -num\n",
    "    if complement in seen:\n",
    "      pairs.append((num, complement))\n",
    "    seen.add(num)\n",
    "  return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Item Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_items(pair_list):\n",
    "    names = sorted(list(set(name for name, _ in pair_list)))\n",
    "    name_pairs = [\" & \".join(pair) for pair in itertools.combinations(names, 2)]\n",
    "    return name_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Departmental Spend By Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select sum(case when department='IT' then amount else null end)IT_Spending,case(when department='hr' then amount else null end)hr_spending,case(when department='marketing' then amount else null end) marketing_spending,case(when department not in ('Marketing','IT','hr') then amount else null end) other_spending,case when transaction_date between '01-01-2023' and '03-30-2023' then q1 when transaction_date between '04-01-2023' and '07-31-2023' then q2 when transaction_date between '08-01-2023' and '12-31-2-2023' then q4 else null end\n",
    "from transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employee Salaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select max(salary),name\n",
    "from employee table\n",
    "group by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee.groupby(\"name\").agg(max(col(\"salary\")).alias(\"max_salary\")).select(col(\"name\"),col(\"max_salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee.groupby(\"name\")[\"salary\"].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance Traveled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select distance,id from rides r\n",
    "join users u on r.id=u.id\n",
    "order by distance desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=rides.merge(users,on=\"id\",how=\"inner\")\n",
    "df[[\"distance\",\"id\"]].sort_values(by=[\"distance\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides.join(users,on=\"id\",how=\"inner\").sort(desc(\"distance\")).select(col(\"distance\"),col(\"id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emails Opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select count(*) from events\n",
    "WHERE action='email_opened'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events=events[events['action']=='email_opened']\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.filter(col(\"actions\")==\"email_opened\").agg(count(col(\"*\")).alias(\"Counts\")).select(col(\"counts\")).show(https://www.interviewquery.com/questions/maximum-common-substring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popular Apple Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select * from (select rank() over(order by count(actions) asc) as rank_actions \n",
    "from events where platform in('Iphone','Ipad') where create_at between '11-01-2020' and '11-30-2020') r where r<=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events=df.copy()\n",
    "df.groupby('actions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t Value via SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH table_column1_stats_CTE AS (\n",
    "    SELECT\n",
    "        AVG(value) AS _mean,\n",
    "        STDDEV(value) AS _stddev,\n",
    "        STDDEV(value) / SQRT(COUNT(*)) AS _se,\n",
    "        COUNT(*) - 1 AS _df\n",
    "    FROM\n",
    "        data\n",
    ")\n",
    "SELECT\n",
    "    _df,\n",
    "    ABS(a._mean - b._mean) / (_stddev/SQRT(_df+1)) AS t_value\n",
    "FROM\n",
    "    table_column1_stats_CTE a, table_column1_stats_CTE b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decreasing Subsequent Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 19, 18, 17, 16, 12, 10, 6, 4, 3]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decreasing_values(arr):\n",
    "     return sorted(arr,reverse=True)\n",
    "arr = [20,17,19,18,12,16,10,4,6,3]\n",
    "decreasing_values(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill None Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 2, 2, 4, 5, 5]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fill_none(input_list):\n",
    "    last_valid = None\n",
    "    result = []\n",
    "    \n",
    "    for item in input_list:\n",
    "        if item is not None:\n",
    "            last_valid = item\n",
    "            result.append(item)\n",
    "        else:\n",
    "            # Replace None with the last valid value\n",
    "            result.append(last_valid)\n",
    "    \n",
    "    return result\n",
    "input_list = [1,2,None,None,4,5,None]\n",
    "fill_none(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid Anagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_anagram(string_1,string_2):\n",
    "  return Counter(string_1)==Counter(string_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# released-patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT discharge_date \n",
    "FROM (\n",
    "    SELECT discharge_date, COUNT(*) AS released_count, \n",
    "    LAG(COUNT(*), 1) OVER (ORDER BY discharge_date) AS prev_released_count \n",
    "    FROM patient_discharges\n",
    "    GROUP BY discharge_date\n",
    ") AS daily_releases\n",
    "WHERE released_count > prev_released_count;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_discharges['discharge_date'] = pd.to_datetime(patient_discharges['discharge_date']) #convert to datetime\n",
    "\n",
    "# Method 1: Using groupby, count, and shift (most similar to SQL)\n",
    "daily_releases = patient_discharges.groupby('discharge_date').size().reset_index(name='released_count')\n",
    "daily_releases['prev_released_count'] = daily_releases['released_count'].shift(1)\n",
    "result = daily_releases[daily_releases['released_count'] > daily_releases['prev_released_count']]['discharge_date']\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_discharges = patient_discharges.withColumn(\"discharge_date\", col(\"discharge_date\").cast(\"date\"))\n",
    "\n",
    "# Method 1: Using groupby, count, and lag (most similar to SQL)\n",
    "daily_releases = patient_discharges.groupBy(\"discharge_date\").count().withColumnRenamed(\"count\", \"released_count\")\n",
    "\n",
    "window_spec = Window.orderBy(\"discharge_date\")\n",
    "daily_releases = daily_releases.withColumn(\"prev_released_count\", lag(\"released_count\", 1).over(window_spec))\n",
    "\n",
    "result = daily_releases.filter(col(\"released_count\") > col(\"prev_released_count\")).select(\"discharge_date\")\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select customer_id,max(created_at),transaction_value from bank_transactions\n",
    "group by customer_id,transaction_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_transactions.groupby([\"customer_id\",\"transaction_value\"])[\"created_at\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_transactions.groupby(\"customer_id\",\"transaction_values\").agg(max(col('created+_at'))).select(col(\"customer_id\"),col(\"transaction_values\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Sorted Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sorted_lists(list1, list2):\n",
    "  return list(heapq.merge(list1, list2))\n",
    "\n",
    "list1 = [1, 3, 5]\n",
    "list2 = [2, 4, 6]\n",
    "\n",
    "merged_list = merge_sorted_lists(list1, list2)\n",
    "print(merged_list)  # Output: [1, 2, 3, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manager Team Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT max(m.team),m.manager_id FROM employee e\n",
    "join managers m on e.manager_id=m.id\n",
    "group by m.manager_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=managers.join(employee,on=\"manager_id\",how=\"inner\")\n",
    "df.groupby(\"manager_id\")[\"team\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "managers.join(\"employee\",on=\"manager_id\",how=\"inner\").groupby(\"manager_id\").agg(max(col(\"team\")).alias(\"max_team\")).select(col(\"max_team\"),col(\"manager_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last Page Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_last_page(int_string):\n",
    "    for ele in int_string:\n",
    "        return ele[-1]\n",
    "input = '12345'\n",
    "get_last_page(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum to n integes python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_to_n(n):\n",
    "    return n * (n + 1) // 2\n",
    "\n",
    "n = int(input(\"Enter a number: \"))\n",
    "result = sum_to_n(n)\n",
    "print(\"Sum of the first\", n, \"integers is:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_to_integers(n):\n",
    "    total=0\n",
    "    for i in range(1,n+1):\n",
    "        total+=i\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employee Salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select max(salary),name\n",
    "from employee table\n",
    "group by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee.groupby('name')['salary'].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee.groupby('salary').agg(max(col(\"salary\")).alias(\"max_salary\")).select(col(\"name\"),col(\"salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Missing Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def missing_number(nums):\n",
    "   for i in range(5):\n",
    "    if i not in nums:\n",
    "      return i\n",
    "nums = [0,1,2,4,5] \n",
    "missing_number(nums) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transactions in the Last 5 Days(see once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT COUNT(*) \n",
    "FROM (\n",
    "    SELECT 1 \n",
    "    FROM bank_transaction \n",
    "    WHERE transaction_date >= DATEADD(day, -5, GETDATE()) \n",
    "    GROUP BY user_id \n",
    ") AS daily_active_users;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.now() - timedelta(days=5)\n",
    "filtered_df = bank_transactions[bank_transactions['transaction_date'] >= start_date]\n",
    "num_unique_users = filtered_df['user_id'].nunique()\n",
    "print(f\"Number of unique users with transactions in the last 5 days: {num_unique_users}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     bigrams \u001b[38;5;241m=\u001b[39m [(words[i], words[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sentence) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bigrams\n\u001b[1;32m----> 9\u001b[0m \u001b[43mfind_bigrams\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m, in \u001b[0;36mfind_bigrams\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_bigrams\u001b[39m(sentence):\n\u001b[1;32m----> 7\u001b[0m     bigrams \u001b[38;5;241m=\u001b[39m [(\u001b[43mwords\u001b[49m[i], words[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sentence) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bigrams\n",
      "\u001b[1;31mNameError\u001b[0m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "sentence = \"\"\"\n",
    "Have free hours and love children? \n",
    "Drive kids to school, soccer practice \n",
    "and other activities.\n",
    "\"\"\"\n",
    "def find_bigrams(sentence):\n",
    "    bigrams = [(words[i], words[i + 1]) for i in range(len(sentence) - 1)]\n",
    "    return bigrams\n",
    "find_bigrams(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Grades\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_grades(grades):\n",
    "     min_grade = min(grades)\n",
    "    max_grade = max(grades)\n",
    "    normalized_grades = [(grade - min_grade) / (max_grade - min_grade) for grade in grades]\n",
    "    return normalized_grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Value Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_value_search(rotated_input, target_value):\n",
    "    for ele,val in enumerate(sample_input):\n",
    "        if ele in target_value:\n",
    "            return ele\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# department-expenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select round(avg(b.amount),2),b.department_id\n",
    "from departments a join expenses a \n",
    "on a.id=b.id\n",
    "where year(b.date)=2022\n",
    "group by b.department_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.merge(departments,expenses,right_on=[\"id\"],left_on=[\"id\"],how=\"inner\")\n",
    "df['date']=pd.to_datetime(df['date'],errors=\"coerce\")\n",
    "df['year']=df[df['date'].dt.year=2022]]\n",
    "df.groupby('department_id')['amount'].mean().round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=departments.join(expenses,departments.id==expenses.id,how=\"inner\")\n",
    "df=df.filter(col(year(\"date\"))=2022)\n",
    "df.groupby('department_id').agg(round(mean(\"amount\")),2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Largest Salary by Department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT max(salary),department\n",
    "group by department\n",
    "order by max(salary) desc\n",
    "limit 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "department.groupby('department')['salary'].max().sort_values(ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "department.groupby('department').agg(max(col('salary')).sort(desc(\"salary\")).select(col(\"department\"),col(\"salary\")).limit(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding The Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics as st\n",
    "def mode (nums : list):\n",
    "    return st.mode(list(nums))\n",
    "\n",
    "nums = [1, 2, 2, 3, 4]\n",
    "mode(list(nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum Numbers As Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_sum(num1, num2):\n",
    "    num1,num2=int(num1),int(num2)\n",
    "    return num1+num2\n",
    "string_sum(num1,num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 180 Day Job Postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with revoked_jobs as(select job_id,count(case when is_revoked=True then 1 else 0 end) from job_postings group by 1)\n",
    "\n",
    "select revoked_jobs/count(*)\n",
    "from revoked_jobs join job_postings b on a.job_id=b.job_id\n",
    "where date_posted > DATEADD(days, -180, CURRENT_DATE); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revoked_jobs = df.groupby('job_id')['is_revoked'].sum().reset_index(name='revoked_count')\n",
    "recent_jobs = df[df['date_posted'] > datetime.now() - timedelta(days=180)]\n",
    "merged_df = pd.merge(revoked_jobs, recent_jobs, on='job_id', how='right')\n",
    "ratio = merged_df['revoked_count'].sum() / len(recent_jobs)\n",
    "print(f\"Ratio of revoked jobs: {ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"date_posted\", col(\"date_posted\").cast(\"date\")) \n",
    "\n",
    "# Calculate revoked_jobs\n",
    "revoked_jobs = df.groupBy(\"job_id\") \\\n",
    "    .agg(sum(when(col(\"is_revoked\"), 1).otherwise(0)).alias(\"revoked_count\"))\n",
    "\n",
    "# Filter for jobs posted within the last 180 days\n",
    "recent_jobs = df.filter(datediff(current_date(), col(\"date_posted\")) <= 180)\n",
    "\n",
    "# Join the DataFrames\n",
    "merged_df = revoked_jobs.join(recent_jobs, on=\"job_id\", how=\"right\")\n",
    "\n",
    "# Calculate the ratio of revoked jobs\n",
    "ratio = merged_df.agg(sum(\"revoked_count\") / count(\"*\")).collect()[0][0]\n",
    "\n",
    "print(f\"Ratio of revoked jobs: {ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.interviewquery.com/questions/liked-and-commented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select count(case when b.action not in('like','comment') then 1 else 0 end)/count(*)\n",
    "from users_table a join events on a.id=b.user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df=users.join(events,users.id==events.id,how=\"inner\")\n",
    "ratio = joined_df.withColumn(\n",
    "    \"not_like_comment\",\n",
    "    when(~col(\"action\").isin([\"like\", \"comment\"]), 1).otherwise(0)\n",
    ").agg(\n",
    "    (count(\"not_like_comment\") / count(\"*\")).alias(\"ratio\")\n",
    ").collect()[0][\"ratio\"]\n",
    "print(f\"Ratio of non-like/comment actions: {ratio}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_users.merge(df_events, on='id')\n",
    "df['not_like_comment'] = df['action'].apply(lambda x: 1 if x not in ('like', 'comment') else 0)\n",
    "ratio = df['not_like_comment'].sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.interviewquery.com/questions/like-tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select count(user_id) as num_users from events\n",
    "where action='like' and created_at='06-06-2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=num_users[(num_users['action']=='like')&(num_users['created_at']=='06-06-2020')]\n",
    "df['user_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=num_users.filter((col('action')='like')&(col('created_at')=='06-06-2020')))\n",
    "df['user_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def cheese_median(df):\n",
    "    return df.fillna(df['Price'].median())\n",
    "cheese_median(df_cheeses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd Highest Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select * from (select *,rank() over(order by sal desc) second_highest from departments)a \n",
    "where second_highest=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sal'].sort_values(ascending=False).iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Window=Window.orderBy(desc(\"sal\"))\n",
    "df.withColumn(\"rank\",rank().over(Window))\n",
    "df.filter(col(\"rank\")==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySQL/the-number-of-rich-customers.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT COUNT(DISTINCT customer_id) AS rich_count\n",
    "FROM Store\n",
    "WHERE amount > 500;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=store[store['amount']>500]\n",
    "df['customer_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.filter(col('amount')>500).select(countDistinct('customer_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low-Quality Problems check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with new_table as(select sum(likes)/sum(likes)+sum(dislikes)*100 as rank,problem_id from problems group by problem_id)\n",
    "    \n",
    "select problem_id\n",
    "from new_table \n",
    "where rank<60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rank_sum']=df['likes'].sum()/df['likes'].sum+df['dislikes'].sum()*100\n",
    "df.groupby('problem_id')['rank_sum']\n",
    "df[df['rank_sum']<60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems.withColumn(\"sum_likes\",sum(col(\"likes\")))\n",
    "problems.withColumn(\"sum_dis_likes\",sum(col(\"likes\")))\n",
    "df.withColumn(\"rank\",sum_likes/sum_likes+dislikes)\n",
    "df.groupby(\"problem_id\").agg(sum(col(\"rank_sum\")).alias(\"rank_sum\")).filter(col(\"rank_sum\")<60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The-Number-of-Rich-Customers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT\n",
    "    COUNT(DISTINCT(customer_id)) AS rich_count\n",
    "FROM\n",
    "    Store\n",
    "WHERE\n",
    "    amount > 500;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store[store['amount']>500].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.filter(col('amount')>500).select(countDistinct(\"customer_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number-of-Times-a-Driver-Was-a-Passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH T AS (SELECT DISTINCT driver_id FROM Rides)\n",
    "SELECT t.driver_id, count(passenger_id) AS cnt\n",
    "FROM\n",
    "    T AS t\n",
    "    LEFT JOIN Rides AS r ON t.driver_id = r.passenger_id\n",
    "GROUP BY 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=rides['driver_id'].unique()\n",
    "df_1=pd.merge(df,rides,right_on=\"driver_id\",left_on=\"passenger_id\",how=\"left\")\n",
    "df_1.groupby(\"driver_id\")[\"passenger_id\"].count().reset_index(name=\"cnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=rides.select(distinct(\"driver_id\")).show()\n",
    "df_1=df.join(rides,df.driver_id==rides.passenger_id,how=\"inner\")\n",
    "df_1.groupb(\"driver_id\").agg(count(col(\"passenger_id\")).alias('cnt')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Traveled Distance 🔒 ## check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select a.user_id,sum(case when b.distance is null then 0 else b.distance end) from users a left rides b on a.user_id=b.user_id\n",
    "group by 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.merge(users,rides,right_on=[\"user_id\"],how=\"left\")\n",
    "df.groupby('user_id')[\"distance\"].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=users.join(rides,users.user_id==rides.user_id,how=\"left\")\n",
    "df.groupby(\"user_id\").agg(sum(col(\"distance\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ticket Agent Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT COUNT(*),COUNT(CASE WHEN agent_id is not null then 0 else 1)ticket_with_agent,count(case when agent_id is null then 0 else 1 end) tickets_without_agent\n",
    "from tickets;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ticket_with_agent']=df['agent_id'].apply(lambda x:1 if x['agent_id'].nontull() else 1)\n",
    "df['ticket_wihtoyt_agent']=df['agent_id'].apply(lambda x:1 if x['agent_id'].istull() else 1)\n",
    "df.agg(counts={'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.withColumn(\"ticket_with_agent\",when(col('ticket_agent').isNull(),1,0))\n",
    "df.withColumn(\"ticket_with_agent\",when(col('ticket_agent').isNotNull(),0,1))\n",
    "df.agg(count(\"*\").alias(\"count\"),count('ticket_with_agent').alias('ticket_with_agent'),count('ticket_without_agent').alias('no ticket')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def word_frequency(sentences):\n",
    "    sentences=str(sentences)\n",
    "    words=Counter(sentences.split())\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'are': 3,\n",
       "         \"'Roses\": 2,\n",
       "         \"['I\": 1,\n",
       "         'love': 1,\n",
       "         \"roses',\": 1,\n",
       "         'the': 1,\n",
       "         \"best',\": 1,\n",
       "         'red': 1,\n",
       "         'violets': 1,\n",
       "         \"blue']\": 1})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "  \"I love roses\",\n",
    "  \"Roses are the best\",\n",
    "  \"Roses are red violets are blue\"\n",
    "]\n",
    "word_frequency(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fl'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "def common_prefix(strings):\n",
    "  return os.path.commonprefix(strings)\n",
    "strings = [\"flowers\", \"flow\", \"flight\"] \n",
    "common_prefix(strings)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = {\n",
    "  'a':3,\n",
    "  'b':4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {\"key1\": 1, \"key2\": 1, \"key3\": 7, \"key4\": 3, \"key5\": 4, \"key6\": 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unique(dictionary):\n",
    "    a=[]\n",
    "    for val in dictionary.values():\n",
    "        for valuses in val:\n",
    "            a.append(valuses)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfind_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m, in \u001b[0;36mfind_unique\u001b[1;34m(dictionary)\u001b[0m\n\u001b[0;32m      2\u001b[0m a\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m dictionary\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m valuses \u001b[38;5;129;01min\u001b[39;00m val:\n\u001b[0;32m      5\u001b[0m         a\u001b[38;5;241m.\u001b[39mappend(valuses)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "find_unique(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m s\u001b[38;5;241m=\u001b[39m{key:\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key,val \u001b[38;5;129;01min\u001b[39;00m dictionary\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(s)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "s={key:set(val) for key,val in dictionary.items()}\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_values(numbers):\n",
    "    res={}\n",
    "    for key,val in numbers.items():\n",
    "        return val[1],val[0]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mswap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumbers\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m, in \u001b[0;36mswap_values\u001b[1;34m(numbers)\u001b[0m\n\u001b[0;32m      2\u001b[0m res\u001b[38;5;241m=\u001b[39m{}\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key,val \u001b[38;5;129;01min\u001b[39;00m numbers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m,val[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "swap_values(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (3686195701.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[17], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    return a\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "full = [1, 2, 3, 4, 5]\n",
    "missing = [1, 2, 3, 5]\n",
    "a=[]\n",
    "for i in full:\n",
    "    if i not in missing:\n",
    "        a.append(i)\n",
    "return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## coin_toss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ng ram count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'banana'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ngrams\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprobability\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FreqDist\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_count(word, n):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_pair_indices(array, target):\n",
    "    seen = {}\n",
    "    for i, num in enumerate(arr):\n",
    "        complement = target - num\n",
    "        if complement in seen:\n",
    "            return [seen[complement], i]  # Found a pair, return indices\n",
    "        seen[num] = i \n",
    "    return [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Group Anagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_anagrams(words):\n",
    "    words.sort(key=lambda x:''.join(sorted(x)))\n",
    "    return [list(group) for _,group in groupby(w,key=lambda x:''.join(sorted(x)))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tout = {}\n",
    "\n",
    "\tdef flatten(x, name=''):\n",
    "\n",
    "\t\t# If the Nested key-value\n",
    "\t\t# pair is of dict type\n",
    "\t\tif type(x) is dict:\n",
    "\n",
    "\t\t\tfor a in x:\n",
    "\t\t\t\tflatten(x[a], name + a + '_')\n",
    "\n",
    "\t\t# If the Nested key-value\n",
    "\t\t# pair is of list type\n",
    "\t\telif type(x) is list:\n",
    "\n",
    "\t\t\ti = 0\n",
    "\n",
    "\t\t\tfor a in x:\n",
    "\t\t\t\tflatten(a, name + str(i) + '_')\n",
    "\t\t\t\ti += 1\n",
    "\t\telse:\n",
    "\t\t\tout[name[:-1]] = x\n",
    "\n",
    "\tflatten(y)\n",
    "\treturn out\n",
    "\n",
    "\n",
    "# Driver code\n",
    "print(flatten_json(unflat_json))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [1, 7, 3, 5, 6]\n",
    "def max_number(nums):\n",
    "    return max(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_number(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String Subsequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string1 = 'abc'\n",
    "string2 = 'asbsc'\n",
    "string3 = 'acedb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##check\n",
    "def is_subsequence(string1,string2):\n",
    "    return string1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"file:///C:/Users/00824732/OneDrive%20-%20Amtrak/Desktop/adderss.csv\")\n",
    "df2=pd.read_csv(\"file:///C:/Users/00824732/OneDrive%20-%20Amtrak/Desktop/df2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['address_1']=df['address'].str.split(n=3,expand=True).get(3)\n",
    "df['city_name']=df['address_1'].str.split(',',n=2,expand=True).get(0)\n",
    "df['zip']=df['address_1'].str.split(',',n=2,expand=True).get(1)\n",
    "df['street']=df['address'].str.split(',',expand=True,n=1).get(0)\n",
    "df=df[['street','city_name','zip']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consolidated=pd.merge(df,df2,right_on=['city'],left_on=['city_name'],how=\"inner\").drop(columns=['city_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>street</th>\n",
       "      <th>zip</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4860 Sunset Boulevard</td>\n",
       "      <td>94105</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3055 Paradise Lane</td>\n",
       "      <td>84103</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>682 Main Street</td>\n",
       "      <td>48204</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>Michigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9001 Cascade Road</td>\n",
       "      <td>64102</td>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5853 Leon Street</td>\n",
       "      <td>33605</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  street     zip            city       state\n",
       "0  4860 Sunset Boulevard   94105   San Francisco  California\n",
       "1     3055 Paradise Lane   84103  Salt Lake City        Utah\n",
       "2        682 Main Street   48204         Detroit    Michigan\n",
       "3      9001 Cascade Road   64102     Kansas City    Missouri\n",
       "4       5853 Leon Street   33605           Tampa     Florida"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_consolidated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>street</th>\n",
       "      <th>city_name</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4860 Sunset Boulevard</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>94105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3055 Paradise Lane</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>84103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>682 Main Street</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>48204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9001 Cascade Road</td>\n",
       "      <td>Kansas City</td>\n",
       "      <td>64102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5853 Leon Street</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>33605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  street       city_name     zip\n",
       "0  4860 Sunset Boulevard   San Francisco   94105\n",
       "1     3055 Paradise Lane  Salt Lake City   84103\n",
       "2        682 Main Street         Detroit   48204\n",
       "3      9001 Cascade Road     Kansas City   64102\n",
       "4       5853 Leon Street           Tampa   33605"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def complete_address(df_addresses: pd.DataFrame, df_cities: pd.DataFrame):\n",
    "    df=pd.read_csv(\"adderss.csv\")\n",
    "    df['address_1']=df['address'].str.split(n=3,expand=True).get(3)\n",
    "    df['city_name']=df['address_1'].str.split(',',n=2,expand=True).get(0)\n",
    "    df['zip']=df['address_1'].str.split(',',n=2,expand=True).get(1)\n",
    "    df['street']=df['address'].str.split(',',expand=True,n=1).get(0)\n",
    "    df=df[['street','city_name','zip']]\n",
    "    df2=pd.read_csv(\"df2.csv\")\n",
    "    df_consolidated=pd.merge(df,df2,right_on=['city'],left_on=['city_name'],how=\"inner\").drop(columns=['city_name'])\n",
    "    return df_consolidated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty Neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT \n",
    "    n.neighborhood_name\n",
    "FROM \n",
    "    neighborhoods n\n",
    "LEFT JOIN \n",
    "    users u \n",
    "ON \n",
    "    n.neighborhood_id = u.neighborhood_id\n",
    "WHERE \n",
    "    u.user_id IS NULL;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above Average Product Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with new_table as(\n",
    "    select a.product_id,b.product_price,avg(a.quantity*b.price) as average_price from transactions a join products b on a.product_id=b.product_id\n",
    "    group by 1,2\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    product_id, \n",
    "    product_price, \n",
    "    average_price\n",
    "FROM \n",
    "    new_table\n",
    "WHERE \n",
    "    product_price > (\n",
    "        SELECT \n",
    "            AVG(b.product_price)\n",
    "        FROM \n",
    "            products b\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select max(created_at)-min(created_at) as no_of_days,user_id from user_sessions\n",
    "where Extract(YEAR FROM created_at)=2020\n",
    "group by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_sessions['created_at']=pd.to_datetime(user_sessions['year'],errors=\"coerce\")\n",
    "uses_sessions['year']=user_sessions[user_sessions['created_at'].dt.year==2022]\n",
    "user_sessions.groupby('user_id').apply(lambda x:x['created_at'].max()-x['created_at'].min()).reset_index(name=\"no_of_days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_session=user_session.filter(year('created_at')=2022)\n",
    "user_session.groupby('user_id').agg(max(\"created_at\")-min(\"created_at\").alias(\"no_of_days\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "def rearranging_digits(input_digits):\n",
    "     digits = list(n)\n",
    "\n",
    "    # Find the pivot point\n",
    "    for i in range(len(digits) - 2, -1, -1):\n",
    "        if digits[i] < digits[i + 1]:\n",
    "            break\n",
    "        else:\n",
    "              return None  # Return None if no larger number can be formed\n",
    "    for j in range(len(digits) - 1, i, -1):\n",
    "        if digits[j] > digits[i]:\n",
    "            # Swap and sort the remaining digits\n",
    "            digits[i], digits[j] = digits[j], digits[i]\n",
    "            return ''.join(digits[:i + 1] + sorted(digits[i + 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'953'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = '395'\n",
    "rearranging_digits(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words in Encrypted String\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_word(encrypted_document, n, target_word):\n",
    "    decrypted_text = \"\"\n",
    "    for char in text:\n",
    "        if char.isalpha():\n",
    "            decrypted_char = chr((ord(char) - 65 - shift) % 26 + 65)\n",
    "            decrypted_text += decrypted_char\n",
    "        else:\n",
    "            decrypted_text += char\n",
    "    return decrypted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decreasing subsequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_decreasing(nums):\n",
    "    \"\"\"\n",
    "    Checks if a list of integers is in decreasing order.\n",
    "\n",
    "    Args:\n",
    "        nums: A list of integers.\n",
    "\n",
    "    Returns:\n",
    "        True if the list is in decreasing order, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(1, len(nums)):\n",
    "        if nums[i] > nums[i - 1]:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has_same_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def has_same_character(strings):\n",
    "    if not strings:\n",
    "        return True\n",
    "    char_set=set(strings[0])\n",
    "    for string in strings[1:]:\n",
    "        if string!=char_set:\n",
    "            return False\n",
    "        return True\n",
    "strings = [\"abc\", \"cba\", \"bca\"]\n",
    "result = has_same_character(strings)\n",
    "print(result)  # Output: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict = {'a': 1, 'b': 2, 'c': 1}\n",
    "\n",
    "def remove_duplicate(my_dict):\n",
    "    return set(values for values in my_dict.values())\n",
    "remove_duplicate(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flowers']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strings = [\"flowers\", \"flow\", \"flight\"] \n",
    "# def common_prefix(strings):\n",
    "#     return strings[0:1]\n",
    "# common_prefix(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select avg(quantity),product_id,year\n",
    "from transactions table\n",
    "group by product_id,year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_table.groupby([\"Product\",\"year\"])[\"quantity\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_table.groupby(\"Product\",\"Year\").agg(acg(col(\"quantity\")).alias(\"agg_quantity\")).select(col(\"product_id\"),col(\"year\"),col(\"agg_quantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 "
     ]
    }
   ],
   "source": [
    "def removeDuplicates(arr):\n",
    "    \n",
    "    # To track seen elements\n",
    "    seen = set()\n",
    "    \n",
    "    # To maintain the new size of the array\n",
    "    idx = 0\n",
    "\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] not in seen:\n",
    "            seen.add(arr[i])\n",
    "            arr[idx] = arr[i]\n",
    "            idx += 1\n",
    "\n",
    "    # Return the size of the array \n",
    "    # with unique elements\n",
    "    return idx\n",
    "\n",
    "# Driver code\n",
    "arr = [1, 2, 2, 3, 4, 4, 4, 5, 5]\n",
    "newSize = removeDuplicates(arr)\n",
    "\n",
    "for i in range(newSize):\n",
    "    print(arr[i], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling Bank Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT\n",
    "    to_char(deposit_date,'%Y-%M-%D') as date\n",
    "    AVG(deposit_amount) OVER (ORDER BY deposit_date ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) AS three_day_avg\n",
    "FROM\n",
    "    deposits;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Bigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bigrams(sentence):\n",
    "    bigrams = [(words[i], words[i + 1]) for i in range(len(sentence) - 1)]\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation Palindrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perm_palindrome(str):\n",
    "    return str[::-1]==str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fewer Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select name from products a join users b on a.user_id=b.id\n",
    "group by name \n",
    "having count(*)<3 or sum(a.order_total)<500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(products, users, left_on='user_id', right_on='id')\n",
    "grouped = merged.groupby('name').agg(count=('name', 'size'), total_order_sum=('order_total', 'sum')).reset_index()\n",
    "result = grouped[(grouped['count'] < 3) | (grouped['total_order_sum'] < 500)]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = products.join(users, products.user_id == users.id, \"inner\")\n",
    "\n",
    "# Group by product name and perform aggregations\n",
    "grouped = merged.groupBy(\"name\").agg(\n",
    "    count(\"*\").alias(\"count\"),\n",
    "    sum(\"order_total\").alias(\"total_order_sum\")\n",
    ")\n",
    "\n",
    "# Apply the filter conditions\n",
    "result = grouped.filter((col(\"count\") < 3) | (col(\"total_order_sum\") < 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def encode(elements) -> list:\n",
    "    unique_elements = np.unique(elements)\n",
    "    mapping = {val: idx for idx, val in enumerate(unique_elements)}\n",
    "    indices = [mapping[val] for val in elements]\n",
    "    one_hot = np.eye(len(unique_elements))[indices]\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge N Sorted Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def sort_lists(lists):\n",
    "    return sorted(itertools.chain.from_iterable(lists))\n",
    "sort_lists(lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Words Filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P', 'e', 't', 'e', 'r', ' ', 'i', 's', ' ']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stopwords_stripped(paragraph, stopwords):\n",
    "    stopwords = [\n",
    "    'I', \n",
    "    'as', \n",
    "    'to', \n",
    "    'you', \n",
    "    'your', \n",
    "    'but', \n",
    "    'be', \n",
    "    'a',\n",
    "]\n",
    "    a=[]\n",
    "    for ele in paragraph:\n",
    "        if ele in stopwords:\n",
    "            break\n",
    "        else:\n",
    "            a.append(ele)\n",
    "    return a\n",
    "paragraph=\"Peter is a guy\"\n",
    "stopwords_stripped(paragraph,\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to get a sample from a standard normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas  as pd\n",
    "def get_standard_normal_sample(size):\n",
    "    return pd.Series(np.random.standard_normal(size))\n",
    "sample = get_standard_normal_sample(100)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Household Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT \n",
    "  city,PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY household) AS median\n",
    "FROM\n",
    "  survey_responses\n",
    "  group by city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('city')['household'].median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"city\").agg(median(\"household\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy_paypal_final_account_balance.sql  ##check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT\n",
    "    account_id,\n",
    "    SUM(\n",
    "        CASE\n",
    "            WHEN transaction_type = 'Deposit' THEN amount\n",
    "            ELSE -amount\n",
    "        END\n",
    "    ) AS final_balance\n",
    "FROM\n",
    "    transactions\n",
    "GROUP BY\n",
    "    account_id;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##check\n",
    "def transaction(transaction_type,amount):\n",
    "    match transaction_type:\n",
    "        case _ if transaction_type=='deposit':\n",
    "            return amount\n",
    "        case _:\n",
    "            return -amount\n",
    "df=transaction.copy()\n",
    "df['amount']= df.apply(lambda row: transaction(row['transaction_type'], row['amount']), axis=1)\n",
    "df.groupby('account_id')['final_balance'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = transactions.withColumn(\n",
    "    \"adjusted_amount\", \n",
    "    when(col(\"transaction_type\") == \"Deposit\", col(\"amount\")).otherwise(-col(\"amount\"))\n",
    ")\n",
    "\n",
    "# Calculate final balance for each account_id\n",
    "final_balance = transactions.groupBy(\"account_id\").agg(sum(\"adjusted_amount\").alias(\"final_balance\"))\n",
    "\n",
    "# Show the results\n",
    "final_balance.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bohemian Goat</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Central Coast Bleu</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cowgirl Mozzarella</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cypress Grove Cheddar</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oakdale Colby</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name  Price\n",
       "0          Bohemian Goat   15.0\n",
       "1     Central Coast Bleu   30.0\n",
       "2     Cowgirl Mozzarella   30.0\n",
       "3  Cypress Grove Cheddar   30.0\n",
       "4          Oakdale Colby   45.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cheeses = {\"Name\": [\n",
    "\"Bohemian Goat\", \n",
    "\"Central Coast Bleu\", \n",
    "\"Cowgirl Mozzarella\", \n",
    "\"Cypress Grove Cheddar\", \n",
    "\"Oakdale Colby\"], \n",
    "\"Price\" : [15.00, None, 30.00, None, 45.00]}\n",
    "\n",
    "df_cheeses = pd.DataFrame(cheeses)\n",
    "\n",
    "\n",
    "def cheese_median(df):\n",
    "    return df.fillna(df['Price'].median())\n",
    "cheese_median(df_cheeses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_x = [1,2,3,4,5]\n",
    "list_y = [1,2,4,5]\n",
    "def one_element_removed(list_x,list_y):\n",
    "  return set(list_x)^set(list_y)\n",
    "one_element_removed(list_x,list_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5th Largest Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_word(word,sentence):\n",
    "    l1=[]\n",
    "    words1=sentence.split()\n",
    "    for ele in word\n",
    "        if ele in words1:\n",
    "            l1.append(ele)\n",
    "        else:\n",
    "            l1.append(word)\n",
    "    return \"\".join(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99, 320, 400, 100.25, 55.2, 0.1]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def fifth_number(num):\n",
    "    res=[]\n",
    "    for ele in num:\n",
    "        if len(ele)>=5:\n",
    "            sorted=sorted(ele,reverse=True)\n",
    "            res.append(sorted[4])\n",
    "        else:\n",
    "            continue\n",
    "    return sorted(res)\n",
    "numlists = [ [1,2,3,4,5], [3,1,2,5,4], [1,2,3,4,5,6,7], \n",
    "[99, 320, 400, 100.25, 55.2, 0.1] ]\n",
    "result = list_fifths(numlists)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.interviewquery.com/questions/5th-largest-number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[99, 320, 400, 100.25, 55.2, 0.1]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numlists = [ [1,2,3,4,5], [3,1,2,5,4], [1,2,3,4,5,6,7], \n",
    "[99, 320, 400, 100.25, 55.2, 0.1] ]\n",
    "\n",
    "def list_fifths(numlists):\n",
    "    return numlists[3]\n",
    "\n",
    "list_fifths(numlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "def extract_first(lst):\n",
    "\tlst=sorted(lst)\n",
    "\tele=[sublist[4] for sublist in lst]\n",
    "\treturn ele.sort(reverse=True)\n",
    "\n",
    "extract_first(numlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ist_of_dict_str = {'x': 0.0, 'y': 5.43}, {'x': 50.0, 'y': 102.78}, {'x': 100.0, 'y': 204.24}\n",
    "# df=pd.DataFrame(ist_of_dict_str)\n",
    "# df.sample(n=70,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_groups = [\n",
    "    ['data scientist', 'data analyst'], \n",
    "    ['data engineer', 'data wrangler'], \n",
    "    ['machine learning engineer'], \n",
    "    ['data' , 'engineer']]\n",
    "text = \"Today, with the advent of data science, different roles have emerged in the industry. Job postings are abundant of many names such as data scientist, data engineer, data wrangler, deep learning specialist, and machine learning specialist to name a few.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 4]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tag_count(tag_groups,text):\n",
    "    eles=Counter(text.split())\n",
    "    results=[]\n",
    "    for group in tag_groups:\n",
    "        count=sum(eles[subword] for subword in group if subword in eles )\n",
    "        results.append(count)\n",
    "    return results\n",
    "tag_count(tag_groups,text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A', '1/2')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fractions import Fraction\n",
    "weights = {'A': 1, 'B': 1}\n",
    "def random_weights(weights):\n",
    "    a=sum(weights.values())\n",
    "    ele={key:f\"{val}/{a}\".replace('','') for key,val in weights.items()}\n",
    "    return ele\n",
    "random_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Three Salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select d.first_name+''+d.last_name,d1.name,d.salary\n",
    "from(select *,rank() over(order by sal desc) as r from departments\n",
    ")d join departments d1 on d.id=d1.id where d.r<=3\n",
    "order by d1.name desc,d.salary desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMS Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'rmse' from 'sklearn.metrics' (C:\\Users\\00824732\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rmse\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_rmse\u001b[39m(y_pred, y_true):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(y_true,y_pred)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'rmse' from 'sklearn.metrics' (C:\\Users\\00824732\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import rmse\n",
    "def calculate_rmse(y_pred, y_true):\n",
    "    return root_mean_squared_error(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'root_mean_squared_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m]\n\u001b[0;32m      2\u001b[0m y_true \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m \u001b[43mroot_mean_squared_error\u001b[49m(y_pred,y_true)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'root_mean_squared_error' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = [3,4,5]\n",
    "y_true = [3,4,5]\n",
    "root_mean_squared_error(y_pred,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurring Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recurring_char(input):\n",
    "    seen = set()\n",
    "    \n",
    "    for char in input:\n",
    "        if char in seen:\n",
    "            return char\n",
    "        seen.add(char)\n",
    "    \n",
    "    return None\n",
    "input = \"interviewquery\"\n",
    "recurring_char(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniquely Staffed Consultants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT d.employee_id,s.made_quota\n",
    "from deals d  join sales_quotas s \n",
    "on d.employee_id=s.employee_id\n",
    "order by d.employee_id asc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=deals.merge(sales_quota,on=\"employee_id\",how=\"inner\")\n",
    "\n",
    "\n",
    "df[[\"employee_id\",\"made_quota\"]].sort_values(by=[\"employee_id\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=deals.merge(sales_quota,on=\"employee_id\",how=\"inner\")\n",
    "df.sort(asc(\"employee_id\")).select(col(\"employee_id\"),col(\"made_quota\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "str = 'adccccbbbbc'\n",
    "def max_repeating(str):\n",
    "    ele=Counter(str)\n",
    "    for key,val in ele.items():\n",
    "        if val>1:\n",
    "            return key\n",
    "\n",
    "max_repeating(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select sum(salary) from employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(col(sum(\"salary\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lifetime Plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT count(*),date_played,user_id\n",
    "from song_plays_table\n",
    "group by date_played,user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"date_played\",\"user_id\").agg(count(col(\"*\")).alias(\"counts\")).select(col(\"date_played\"),col(\"user_id\"),col(\"counts\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_plays_table.groupby([\"date_played\",\"user_id\"]).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_list = [8, 16, 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m   a\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(numbers)\n\u001b[0;32m      4\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(gcd(a))\n\u001b[1;32m----> 5\u001b[0m \u001b[43mgcd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mint_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m, in \u001b[0;36mgcd\u001b[1;34m(numbers)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgcd\u001b[39m(numbers):\n\u001b[0;32m      3\u001b[0m   a\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(numbers)\n\u001b[1;32m----> 4\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[43mgcd\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m, in \u001b[0;36mgcd\u001b[1;34m(numbers)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgcd\u001b[39m(numbers):\n\u001b[0;32m      3\u001b[0m   a\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(numbers)\n\u001b[1;32m----> 4\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[43mgcd\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m)\n",
      "    \u001b[1;31m[... skipping similar frames: gcd at line 4 (2974 times)]\u001b[0m\n",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m, in \u001b[0;36mgcd\u001b[1;34m(numbers)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgcd\u001b[39m(numbers):\n\u001b[0;32m      3\u001b[0m   a\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(numbers)\n\u001b[1;32m----> 4\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[43mgcd\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def gcd(numbers):\n",
    "  a=str(numbers)\n",
    "  return int(gcd(a))\n",
    "gcd(int_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT * FROM players\n",
    "games_played betwee 5 and 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players[players[\"game_played\"].between(5,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.filter(col(\"game_played\").between(5,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marked Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [\"ball\",\"ninja\",\"plan\"]\n",
    "list2 = [\"cat\",\"egg\",\"zoo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_lists(list1, list2):\n",
    "    return list(zip(list1,list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ball', 'cat'), ('ninja', 'egg'), ('plan', 'zoo')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mark_lists(list1,list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Duplicate Numbers in a List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_duplicates(nums):\n",
    "    seen = set()\n",
    "    duplicates = set()\n",
    "    \n",
    "    for item in nums:\n",
    "        if item in seen:\n",
    "            duplicates.add(item)\n",
    "        else:\n",
    "            seen.add(item)\n",
    "    \n",
    "    return list(duplicates)\n",
    "\n",
    "nums = [1, 2, 3, 1, 2, 3]\n",
    "find_duplicates(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of Matrix Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m matrix \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m], [\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m]]\n\u001b[0;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39msum(matrix)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "np.sum(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT attribute_name, COUNT(*) AS frequency\n",
    "FROM table1 \n",
    "INNER JOIN table2 ON table1.join_key = table2.join_key\n",
    "INNER JOIN table3 ON table2.join_key2 = table3.join_key2\n",
    "WHERE table3.attribute_name IS NOT NULL -- Account for NULLs\n",
    "GROUP BY attribute_name\n",
    "ORDER BY frequency DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.merge(table1,table2,right_on=[\"join_key\"],left_on=[\"join_key\"],how=\"inner\")\n",
    "df_1=pd.merge(df,table3,right_on=[\"join_key2\"],left_on=[\"join_key2\"],how=\"inner\")\n",
    "df_2=df_1[df_1['attribute_name'].notnull()]\n",
    "df_3=df_2.groupby(\"attribute_name\").size().reset_index(name=\"frequency\")\n",
    "df_3.sort(desc(\"frequency\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=table1.join(table2,table1.join_key==table2.join_key,how=\"inner\")\n",
    "df1=df.join(table3,df.join_key==df.join_key,how=\"inner\")\n",
    "df1.groupby(\"attribute_name\").agg(count(col(\"*\")).alias(\"frequency_count\")).sort(desc(\"frequency_count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a users table, write a query to return only its duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select * from users\n",
    "group by id\n",
    "having count(*)>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_table.groupby(\"id\").agg(count).filter(col(\"*\")>1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "res=[1,3,5,7,1]\n",
    "a=Counter(res)\n",
    "de=[]\n",
    "for key,val in a.items():\n",
    "    if val>1:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "user_ids = [103, 105, 105, 107, 106, 103, 102, 108, 107, 103, 102]\n",
    "tips = [2, 5, 1, 0, 2, 1, 1, 0, 0, 2, 2]\n",
    "a=list(zip(user_ids,tips))\n",
    "max(a[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'department': ['A', 'A', 'B', 'B', 'C'],\n",
    "        'sales': [10, 20, 5, 110, 2]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Group by department and calculate the sum of sales\n",
    "grouped = df.groupby('department')['sales'].sum()\n",
    "\n",
    "# Filter the groups based on the having condition\n",
    "result = grouped[grouped > 15].idxmax()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a15', 'a3', 'b12', 'b7', 'c20', 'c4']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [\"b12\", \"a15\", \"b7\", \"a3\", \"c4\", \"c20\"]\n",
    "sorted(arr,reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'are': 3,\n",
       "         \"'Roses\": 2,\n",
       "         \"['I\": 1,\n",
       "         'love': 1,\n",
       "         \"roses',\": 1,\n",
       "         'the': 1,\n",
       "         \"best',\": 1,\n",
       "         'red': 1,\n",
       "         'violets': 1,\n",
       "         \"blue']\": 1})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "sentences = [\n",
    "  \"I love roses\",\n",
    "  \"Roses are the best\",\n",
    "  \"Roses are red violets are blue\"\n",
    "]\n",
    "sentences=str(sentences)\n",
    "Counter(sentences.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 5), ('sauna', 2), ('of', 2)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "posting = \"\"\"\n",
    "Herbal sauna uses the healing properties of herbs in combination with distilled water.   \n",
    "The water evaporates and distributes the effect of the herbs throughout the room.   \n",
    "A visit to the herbal sauna can cause real miracles, especially for colds. \n",
    "\"\"\"  \n",
    "n = 3\n",
    "Counter(posting.split()).most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekly Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_week_pandas(timestamps):\n",
    "  df = pd.DataFrame({'timestamp': timestamps})\n",
    "  df['week_start'] = df['timestamp'] - pd.to_timedelta(df['timestamp'].dt.weekday, unit='D')\n",
    "  grouped_df = df.groupby('week_start')['timestamp'].apply(list).reset_index()\n",
    "\n",
    "  return grouped_df['timestamp'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 26, 25, 22, 21, 14, 10, 5]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [25,30,21,22,14,10,5,26]\n",
    "def decreasing_values(arr):\n",
    "    return sorted(arr,reverse=True)\n",
    "decreasing_values(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr= [1, [2, 3], [4, [5, 6]], 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten_array(arr):\n",
    "    a=[]\n",
    "    for ele in arr:\n",
    "        if isinstance(ele,list):\n",
    "            a.extend(flatten_array(ele))\n",
    "        else:\n",
    "            a.append(ele)\n",
    "    return a\n",
    "flatten_array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "input =  '12345'\n",
    "for ele in input.split():\n",
    "     print(ele[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select All Flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT * FROM flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(col(\"*\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Ride Duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select avg(end_dt-start_dt) aov, id\n",
    "from rides table\n",
    "group by id\n",
    "order by passenger_user_id asc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides_table[\"aov\"]=rides['end_dt'] - rides['start_dt'] \n",
    "df=rides.groupby('id')['aov'].mean().reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"aov\",col(\"end_dt\")-col(\"start_dt\"))\n",
    "df.groupby(\"aov\").agg(mean(col(\"aov\")).alias(\"total\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good Grades and Favorite Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def grades_colors(students_df: pd.DataFrame):\n",
    "    students_df=df.copy()\n",
    "    df_filtered=df[(df['color']=='green')&(df['grade']>90)]\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_df((col('color')=='green')&(col('grade')>90)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_characters(input_list):\n",
    "    result = []\n",
    "    for s in string_list:\n",
    "        result.append(len(set(s)) <= 1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prime Numbers Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_prime_numbers(nums):\n",
    "   primes = []\n",
    "    for num in range(2, limit + 1):\n",
    "        is_prime = True\n",
    "        for i in range(2, int(num**0.5) + 1):\n",
    "            if num % i == 0:\n",
    "                is_prime = False\n",
    "                break\n",
    "        if is_prime:\n",
    "            primes.append(num)\n",
    "    return primes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximal_substring(string1, string2):\n",
    "    max_substring = \"\"\n",
    "    for i in range(len(s)):\n",
    "        if s[i:] > max_substring:\n",
    "            max_substring = s[i:]\n",
    "    return max_substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select *(select rank() over(order by created_at)rows from transactions)\n",
    "where rows%4=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['rank']=df['created_at'].rank(method=\"dense\").astype(int)\n",
    "df_1[df_1['rank']%4==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"rank\",over(Order by created_at))\n",
    "df.filter(col(\"rank\")%4==0).select(\"*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort Strings\n",
    "# # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'banana', 'cat', 'football', 'zoo']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sorting(array):\n",
    "    return sorted(array)\n",
    "array = [\"apple\", \"cat\", \"banana\", \"zoo\", \"football\"]\n",
    "sorting(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select max(quantity),year,product_id from transactions\n",
    "group by product_id,year\n",
    "order by year,product_id desc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.groupby('product','year').agg(max(count(\"quantity\")).alias(\"max_quantity\")).sort(desc(\"year\")).select(col(\"year\"),col(\"product_id\"),col(\"max_quantity\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.groupby([\"Product\",\"Year\"])[\"quantity\"].max().rest_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id\tranking\tvalue\n",
    "1001\t1\t1000\n",
    "1001\t2\tNaN\n",
    "1001\t3\t1200\n",
    "1002\t1\t1500\n",
    "1002\t2\t1250\n",
    "1002\t3\tNaN\n",
    "1003\t1\t1100\n",
    "1003\t2\tNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def previous_nan_values(clients_df):\n",
    "    return clients_df[clients_df.bfill(clients_df['value'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PYSPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous NaN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def previous_nan_values(clients_df):\n",
    "    return clients_df[clients_df.bfill(clients_df['value'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_spec = Window.partitionBy(\"id\").orderBy(\"id\").rowsBetween(Window.unboundedPreceding, 0)\n",
    "df_bfill = df.withColumn(\"value_bfill\", last(\"value\", ignorenulls=True).over(window_spec))\n",
    "df_bfill.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a SQL query to find the average number of accepted friend requests for each age group and order the results in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT\n",
    "    u.age_group,\n",
    "    AVG(CASE WHEN ra.acceptor_id IS NOT NULL THEN 1 ELSE 0 END) AS avg_accepted_requests\n",
    "FROM\n",
    "    Users u\n",
    "LEFT JOIN\n",
    "    Friend_Requests fr ON u.user_id = fr.requester_id\n",
    "LEFT JOIN\n",
    "    Request_Accepted ra ON fr.request_id = ra.request_id\n",
    "GROUP BY\n",
    "    u.age_group\n",
    "ORDER BY\n",
    "    avg_accepted_requests DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.merge(user,friends,right_on=[\"user_id\"],left_on=[\"requester_id\"],how=\"left\")\n",
    "df_1=pd.merge(df,requester_accepted,right_on=[\"requester_id\"],left_on=[\"request_id\"],how=\"left\",suffix=('_x','_y'))\n",
    "d_2=df_1.groupby(\"age_group\")[\"acceptor_id_y\"].mean().reset_index()\n",
    "df_2.sort_values(by=[\"acceptor_id\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=friends_request.join(users,friends_request.user_id==user.requester_id,how=\"left\")\n",
    "df_1=df.join(request_accepted,df.request_id==request_accepted.request_id,how=\"left\")\n",
    "df.groupby(\"age_group\").agg(mean(when(col('acceptor_id').isnotnull(),1,0)).alias(\"avg_accepted_request\")).sort(desc(\"avg_accepted_requests\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMS Confirmations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select count(distinct b.phone_numbers ),a.country,a.carrier from sms_sends a join confirmers b on a.phone_numbr=b.phone_number and b.date=02-28-2020'\n",
    "group by 2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.merge(sms_sends,confirmers,right_on=[\"phone_number\"],how='inner')\n",
    "df[df['date']=='02-28-2020'].groupby(['carrier','country'])[\"phone_number\"].nunqiue().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sends.join(confirmers,sends.phone_number==confirmers.phone_numbers,how=\"inner\")\n",
    "df.filter(col('date')=='02-28-2020').groupby(\"carrier\",\"country\").agg(countDistinct(\"phone_number\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returning Last Element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def last_element(int_list):\n",
    "    return int_list[-1]\n",
    "\n",
    "\n",
    "int_list = [0,1,2]\n",
    "last_element(int_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_buss_days(date1, date2):\n",
    "    return len(pd.bdate_range(date1,date2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, date_add\n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "@udf(returnType=DateType())\n",
    "def add_business_days(date, days):\n",
    "    return new_date\n",
    "\n",
    "df = df.withColumn(\"new_date\", add_business_days(df.date_column, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.89"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics as st\n",
    "import numpy as np\n",
    "def get_variance(test_list):\n",
    "    return round(np.var(test_list),2)\n",
    "test_list = [6, 7, 3, 9, 10, 15]\n",
    "get_variance(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 Turnover Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH EmployeeProjectCounts AS (\n",
    "  SELECT\n",
    "    e.id,\n",
    "    e.salary,\n",
    "    COUNT(p.project_id) AS project_count\n",
    "  FROM\n",
    "    employees e\n",
    "  JOIN projects p ON e.id = p.employee_id\n",
    "  GROUP BY\n",
    "    e.id, e.salary\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  id,\n",
    "  salary\n",
    "FROM\n",
    "  EmployeeProjectCounts\n",
    "WHERE\n",
    "  project_count >= 3\n",
    "ORDER BY\n",
    "  salary ASC\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=pd.merge(employee,projects,right_on=\"id\",left_on=\"employee_id\",how=\"inner\")\n",
    "df_1.groupby([\"id\",\"salary\"])['project_id'].count().reset_index(name='project_count')\n",
    "df_2=df_1[df_1[\"project_count\"]>=3]\n",
    "df_2.sort_values(by=['salary'],ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=employee.join(project,employee.id==project.employee_id,how=\"inner\")\n",
    "df_2=df_1.groupby(\"id\",\"salary\").agg(count(\"project_id\").alias(\"total_count\")).show()\n",
    "df_2.filter(col(\"total_count\")>=3).sort(asc(\"salary\")).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liked and Commented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select count(case when b.action not in('like','comment') then 1 else 0 end)/count(*)\n",
    "from users_table a join events on a.id=b.user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filtered_events = events[~events['action'].isin(['like', 'comment'])]\n",
    "non_like_comment_count = filtered_events.shape[0]\n",
    "total_count = events.shape[0]\n",
    "proportion = non_like_comment_count / total_count\n",
    "\n",
    "print(proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = users_table.join(events, on='id', how='left')\n",
    "filtered_count = joined_df.filter(F.col('action').notin(['like', 'comment'])).count()\n",
    "total_count = joined_df.count()\n",
    "ratio = F.expr(F.lit(filtered_count) / total_count)\n",
    "print(ration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t Value via Pandas ##checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "stats.ttest_1samp(data, pop_mean)\n",
    "\n",
    "def t_score(mu0, df: pd.DataFrame):\n",
    "    return stats.ttest_1samp(data, mu0)\n",
    "\n",
    "sample_mean = data['var'].mean()\n",
    "sample_std = data['var'].std()\n",
    "sample_size = len(data['var'])\n",
    "t_value = (sample_mean - hypothesized_mean) / (sample_std / np.sqrt(sample_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order Addresses https://www.interviewquery.com/questions/order-addresses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform Car Maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT manufacturer_name \n",
    "FROM cars\n",
    "ORDER BY RAND() \n",
    "LIMIT 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_row = cars.sample(n=1)\n",
    "manufacturer_name = random_row['manufacturer_name'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.orderBy(rand()).limit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free Seats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT\n",
    "  f.flight_id,\n",
    "  f.seats - COUNT(fp.flight_id) AS unpurchased_seats\n",
    "FROM\n",
    "  flights f\n",
    "LEFT JOIN flight_purchases fp ON f.flight_id = fp.flight_id\n",
    "GROUP BY\n",
    "  f.flight_id, f.seats;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(flights, flight_purchases, on='flight_id', how='left')\n",
    "grouped_df = merged_df.groupby('flight_id').agg({'flight_id': 'count'})\n",
    "grouped_df.rename(columns={'flight_id': 'purchased_seats'}, inplace=True)\n",
    "result_df = pd.merge(flights, grouped_df, on='flight_id', how='left')\n",
    "result_df['unpurchased_seats'] = result_df['seats'] - result_df['purchased_seats'].fillna(0)\n",
    "result_df = result_df[['flight_id', 'unpurchased_seats']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = flights.join(flight_purchases, on=\"flight_id\", how=\"left\")\n",
    "\n",
    "\n",
    "unpurchased_seats_df = joined_df.groupBy(\"flight_id\", \"seats\").agg(\n",
    "    (col(\"seats\") - count(\"flight_id\")).alias(\"unpurchased_seats\")\n",
    ")\n",
    "unpurchased_seats_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_change(cents):\n",
    "    coin_count = 0\n",
    "    for value in coin_values:\n",
    "        while cents >= value:\n",
    "            cents -= value\n",
    "            coin_count += 1\n",
    "\n",
    "    return coin_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum Absolute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_distance(test_input):\n",
    "    for ele in range(test_input):\n",
    "        min_difference=min(test_input[ele]-test_input[ele+1])\n",
    "    return min_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Released Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT release_date\n",
    "FROM (\n",
    "    SELECT release_date, COUNT(*) AS num_discharges,\n",
    "           LAG(COUNT(*)) OVER (ORDER BY release_date) AS prev_day_discharges\n",
    "    FROM released_patients table\n",
    "    GROUP BY discharge_date\n",
    ") subquery\n",
    "WHERE num_discharges > prev_day_discharges;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rain on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def median_rainfall(df_rain):\n",
    "    return df_rain['Inches'].notnull().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Fibonacci Sequence in Three Different Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci_recursive(n):\n",
    "    if n<2:\n",
    "        return 0\n",
    "      return fibonacci(num - 1) + fibonacci(num - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-gram Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(n,string):\n",
    "    n_gram_dict={}\n",
    "    for i in range(len(string)-n+1):\n",
    "        ngram=word[i:i+n]\n",
    "        ngram_dict[ngram]=ngram_dict.get(ngram,0)+1\n",
    "    return n_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing Numeric Strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_strings(num_str1, num_str2):\n",
    "    num_str1,num_str2=int(num_str1),int(num_str2)\n",
    "    ele=num_str1+num_str2\n",
    "    return str(ele)f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(sentences):\n",
    "    import re\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_tf(document):\n",
    "    document = re.sub(r'[^\\w\\s]', '', document).lower()\n",
    "    # Split the document into terms (words)\n",
    "    terms = document.split()\n",
    "\n",
    "    # Calculate the total number of terms in the document\n",
    "    total_terms = len(terms)\n",
    "\n",
    "    # Calculate TF values using Counter\n",
    "    term_counts = Counter(terms)\n",
    "\n",
    "    # Calculate TF for each term\n",
    "    tf_values = {}\n",
    "    for term, count in term_counts.items():\n",
    "        tf_values[term] = count / total_terms\n",
    "\n",
    "    return tf_values\n",
    "\n",
    "# Example Usage:\n",
    "document = \"I have a nice car with a nice tires\"\n",
    "tf_values = calculate_tf(document)\n",
    "print(tf_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over 100 Dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def transactions_over_100(df_transactions: pd.DataFrame, df_products: pd.DataFrame):\n",
    "    merged_df=pd.merge(df_transactions,df_products,right_on=[\"product_id\"],left_on=[\"product_id\"],how=\"inner\")\n",
    "    merged_df['total_gt_100']=merged_df.apply(lambda x:x['amount']>100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Book Availability Update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def update_availability(book_id: int, copies: int, df_books: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.loc[df.book_id == 3,'copies_available'] = copies\n",
    "\n",
    "copies=8\n",
    "update_availability(book_id,copies,df_books)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT count() over(partition by user order by user_id)\n",
    "from users join comments on a.id=b.user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.merge(users,join,right_on=[\"id\"],left_on=['user_id'],how='inner')\n",
    "df.sort_values(by=['order_id'])\n",
    "df.groupby('user').cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative Sales By Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT product_id,date,sum(sales) over(partition by product_id order by product_id,date)\n",
    "from sales\n",
    "group by 1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.groupby('product_id','date').cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alphabet Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<string>:3\u001b[1;36m\u001b[0m\n\u001b[1;33m    alphabet_sums = []\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def sum_alphabet(words):\n",
    "    words = string.split()\n",
    "  alphabet_sums = []\n",
    "\n",
    "  for word in words:\n",
    "    word_sum = sum(ord(char) - ord('a') + 1 for char in word)\n",
    "    alphabet_sums.append(word_sum)\n",
    "\n",
    "  return alphabet_sums\n",
    "words = [\"sport\" , \"good\" , \"bad\"]\n",
    "sum_alphabet(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Unique Song ## check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with new_table as(select id,rank() over(order by name desc) ranks from song_plays_table a)\n",
    "select min(a.date_played),b.name,a.name from song_plays a join user b on a.user_id=b.user_id and ranks=3\n",
    "group by 2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=songs_plays_table.groupby('id')['name'].rank(method=\"desc\").reset_index()\n",
    "df_1=pd.merge(df,songs_play_tabel,right_on=[\"id\"],left_on=[\"id\"],how=\"inner\")\n",
    "df[df['rank']==3].groupby(['df_name','df_1_name'])[\"date_played\"].min().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_play_table.withColumn(\"rank\",over(order by name desc))\n",
    "songs_plays_table.filter(col('rank')==3).groupby('id','name').agg(min(col('Date'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments Histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT count(*),a.user_id\n",
    "FROM userstable u\n",
    "join commentstable c\n",
    "on u.neighbourhood_id=c.user_id and where to_char(created_at,'Month')='Jan' and to_char(created_at,'Year')=2021\n",
    "group by 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=userstable.join(commentstable,userstable.user_id==comments_table.user_id,how=\"inner\").show()\n",
    "df.groupby(\"user_id\").agg(count(col(\"*\")).alias(\"total_count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.merge(userstable,commentstable,right_on=\"neighbourhood\",left_on=\"user_id\")\n",
    "df=df[df['created'].dt.month_name]\n",
    "df.groupby(\"user_id\").size().reset_index(name=\"count\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_number(x, y=0, count=1):\n",
    "    result = []\n",
    "    for _ in range(count):\n",
    "        result.append(random.randint(x, y))\n",
    "    return result "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
